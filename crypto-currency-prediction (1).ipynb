{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/LTC-USD.csv\n",
      "/kaggle/input/BCH-USD.csv\n",
      "/kaggle/input/BTC-USD.csv\n",
      "/kaggle/input/ETH-USD.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>BTC-low</th>\n",
       "      <th>BTC-high</th>\n",
       "      <th>BTC-open</th>\n",
       "      <th>BTC-close</th>\n",
       "      <th>BTC-volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528968660</td>\n",
       "      <td>6489.549805</td>\n",
       "      <td>6489.560059</td>\n",
       "      <td>6489.560059</td>\n",
       "      <td>6489.549805</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1528968720</td>\n",
       "      <td>6487.370117</td>\n",
       "      <td>6489.560059</td>\n",
       "      <td>6489.549805</td>\n",
       "      <td>6487.379883</td>\n",
       "      <td>7.706374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1528968780</td>\n",
       "      <td>6479.410156</td>\n",
       "      <td>6487.370117</td>\n",
       "      <td>6487.370117</td>\n",
       "      <td>6479.410156</td>\n",
       "      <td>3.088252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1528968840</td>\n",
       "      <td>6479.410156</td>\n",
       "      <td>6479.419922</td>\n",
       "      <td>6479.419922</td>\n",
       "      <td>6479.410156</td>\n",
       "      <td>1.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1528968900</td>\n",
       "      <td>6475.930176</td>\n",
       "      <td>6479.979980</td>\n",
       "      <td>6479.410156</td>\n",
       "      <td>6479.979980</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time      BTC-low     BTC-high     BTC-open    BTC-close  BTC-volume\n",
       "0  1528968660  6489.549805  6489.560059  6489.560059  6489.549805    0.587100\n",
       "1  1528968720  6487.370117  6489.560059  6489.549805  6487.379883    7.706374\n",
       "2  1528968780  6479.410156  6487.370117  6487.370117  6479.410156    3.088252\n",
       "3  1528968840  6479.410156  6479.419922  6479.419922  6479.410156    1.404100\n",
       "4  1528968900  6475.930176  6479.979980  6479.410156  6479.979980    0.753000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('/kaggle/input/LTC-USD.csv', names = [\"time\",\"LTC-low\",\"LTC-high\",\"LTC-open\",\"LTC-close\",\"LTC-volume\"])\n",
    "\n",
    "\n",
    "data2 = pd.read_csv('/kaggle/input/BTC-USD.csv', names = [\"time\",\"BTC-low\",\"BTC-high\",\"BTC-open\",\"BTC-close\",\"BTC-volume\"])\n",
    "\n",
    "\n",
    "data3= pd.read_csv('/kaggle/input/ETH-USD.csv', names = [\"time\",\"ETH-low\",\"ETH-high\",\"ETH-open\",\"ETH-close\",\"ETH-volume\"])\n",
    "\n",
    "\n",
    "data4 = pd.read_csv('/kaggle/input/BCH-USD.csv', names = [\"time\",\"BCH-low\",\"BCH-high\",\"BCH-open\",\"BCH-close\",\"BCH-volume\"])\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "LTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n",
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083  \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400  \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646  \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759  \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300  \n"
     ]
    }
   ],
   "source": [
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
    "for ratio in ratios:  # begin iteration\n",
    "    print(ratio)\n",
    "    dataset = f'/kaggle/input/{ratio}.csv'  # get the full path to the file.\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    if len(main_df)==0:  # if the dataframe is empty\n",
    "        main_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "print(main_df.head())  # how did we do??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "...                   ...        ...     ...\n",
      "1535214960      58.020000  58.020000       0\n",
      "1535215020      58.009998  58.080002       1\n",
      "1535215080      58.020000        NaN       0\n",
      "1535215140      58.020000        NaN       0\n",
      "1535215200      58.080002        NaN       0\n",
      "\n",
      "[97723 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "\n",
    "#print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\"]])\n",
    "\n",
    "main_df['target'] = list(map(classify,main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df['future']))\n",
    "\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]])\n",
    "\n",
    "main_df.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "...                   ...        ...     ...\n",
      "1535214780      58.009998  58.020000       1\n",
      "1535214840      58.009998  58.009998       0\n",
      "1535214900      58.020000  58.020000       0\n",
      "1535214960      58.020000  58.020000       0\n",
      "1535215020      58.009998  58.080002       1\n",
      "\n",
      "[97720 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531906380\n"
     ]
    }
   ],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "\n",
    "last_5pct = times[-int(0.5*len(times))]\n",
    "print(last_5pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_main_df =  main_df[(main_df.index)>=last_5pct]\n",
    "main_df =  main_df[(main_df.index)<last_5pct]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future',axis = 1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] =df[col].pct_change()\n",
    "            df = df.dropna()\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "            \n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    sequential_data =[]\n",
    "    prev_days = deque(maxlen = SEQ_LEN)\n",
    "    \n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        \n",
    "        if(len(prev_days)==SEQ_LEN):\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "            \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys = []\n",
    "    sell = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target ==0:\n",
    "            sell.append([seq,target])\n",
    "        else:\n",
    "            buys.append([seq,target])\n",
    "\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sell)\n",
    "\n",
    "    lower = min(len(buys),len(sell))\n",
    "\n",
    "    buys = buys[:lower]\n",
    "    sell = sell[:lower]\n",
    "\n",
    "    sequential_data = buys+sell\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X= []\n",
    "    y= []\n",
    "\n",
    "    for seq,target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X),np.array(y)\n",
    "    \n",
    "\n",
    "\n",
    "train_x,train_y = preprocess_df(main_df)\n",
    "validation_x,validation_y = preprocess_df(validation_main_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 41084 validation: 40670\n"
     ]
    }
   ],
   "source": [
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "#print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "#print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  # a unique name for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "642/642 [==============================] - 14s 22ms/step - loss: 0.7326 - accuracy: 0.5143 - val_loss: 0.6981 - val_accuracy: 0.5129\n",
      "Epoch 2/10\n",
      "642/642 [==============================] - 13s 20ms/step - loss: 0.6928 - accuracy: 0.5338 - val_loss: 0.6901 - val_accuracy: 0.5298\n",
      "Epoch 3/10\n",
      "642/642 [==============================] - 13s 20ms/step - loss: 0.6877 - accuracy: 0.5417 - val_loss: 0.6899 - val_accuracy: 0.5364\n",
      "Epoch 4/10\n",
      "642/642 [==============================] - 14s 21ms/step - loss: 0.6853 - accuracy: 0.5532 - val_loss: 0.6850 - val_accuracy: 0.5512\n",
      "Epoch 5/10\n",
      "642/642 [==============================] - 13s 20ms/step - loss: 0.6806 - accuracy: 0.5618 - val_loss: 0.6850 - val_accuracy: 0.5566\n",
      "Epoch 6/10\n",
      "642/642 [==============================] - 13s 20ms/step - loss: 0.6772 - accuracy: 0.5710 - val_loss: 0.6900 - val_accuracy: 0.5503\n",
      "Epoch 7/10\n",
      "642/642 [==============================] - 13s 21ms/step - loss: 0.6747 - accuracy: 0.5744 - val_loss: 0.6847 - val_accuracy: 0.5605\n",
      "Epoch 8/10\n",
      "642/642 [==============================] - 13s 21ms/step - loss: 0.6691 - accuracy: 0.5864 - val_loss: 0.6913 - val_accuracy: 0.5448\n",
      "Epoch 9/10\n",
      "642/642 [==============================] - 13s 21ms/step - loss: 0.6620 - accuracy: 0.5999 - val_loss: 0.6919 - val_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "642/642 [==============================] - 13s 20ms/step - loss: 0.6518 - accuracy: 0.6142 - val_loss: 0.7116 - val_accuracy: 0.5402\n",
      "Test loss: 0.711593508720398\n",
      "Test accuracy: 0.5402262210845947\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "import tensorflow as tf\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "#checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    ")\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
